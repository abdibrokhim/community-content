---
title: "8 mind blowing things you might have missed about GPT-4"
description: "A deep look into GPT-4 Technical Report and cherry picking some of informations you might have missed"
image: "https://storage.googleapis.com/lablab-static-eu/images/blog/gpt-4-image-1.jpg"
authorUsername: "Marek"
---

## GPT-4 is out!

Everyone has been talking about OpenAI since 30.11.2022, the day ChatGPT was released. We saw people playing with it through all social media platforms, journalists trying to jailbreak it or researchers incorporating it as a co-author of their work. It even co-wrote one of the South Park episodes!

Before the dust settled Microsoft invested in OpenAI and included it as a feature for Azure services and Bing search. On the 1.3.2023 OpenAI shared Whisper’s and ChatGPT API so all devs can build apps using the cutting edge technology. We all knew that GPT-4 is coming, but I don’t think many of us predicted it to be launched so fast!

On 14.03.2023 OpenAI introduced GPT-4 and I might say it is, as predicted, a huge step forward. 

Here are some 8 interesting facts you might have missed as many people prefer to go only through presentation, rather than research paper. But at lablab.ai we always want to know everything AI related and we are going to do this job for you. So, let’s dive in!

### GPT-4 is powering Bing!

As you might read on Microsoft’s blog, it is official! Also if you played with Bing chatbot you already interacted with it for the past 5 weeks, but now we are aware of it. So don’t wait more and sign in to the waitlist to test it yourself. We will soon write more about it, so stay tuned!

### Some testers still prefer GPT-3.5 outputs!

“GPT-4 substantially improves over previous models in the ability to follow user intent [57]. On
a dataset of 5,214 prompts submitted to ChatGPT [58] and the OpenAI API [41], the responses
generated by GPT-4 were preferred over the responses generated by GPT-3.5 on 70.2% of prompts.”

### The training of the model is secret!

“Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method, or similar.”

### Still has a knowledge cut-off

<Img src="https://storage.googleapis.com/lablab-static-eu/images/blog/gpt-4-image-2.jpg" />

GPT-4 generally lacks knowledge of events that have occurred after the vast majority of its pre-training data cuts off in September 2019 , and does not learn from its experience. It can sometimes make simple reasoning errors which do not seem to comport with competence across so many domains, or be overly gullible in accepting obviously false statements from a user. It can fail at hard problems the same way humans do, such as introducing security vulnerabilities into code it produces.

### Context is doubled (and for limited access it is 8 times bigger)

“gpt-4 has a context length of 8,192 tokens. We are also providing limited access to our 32,768–context (about 50 pages of text) version, gpt-4-32k”

### It is much better at language

<Img src="https://storage.googleapis.com/lablab-static-eu/images/blog/gpt-4-plot.jpg" />

### GPT-4 hallucinates less

Despite its capabilities, GPT-4 has similar limitations as earlier GPT models. Most importantly, it still is not fully reliable (it “hallucinates” facts and makes reasoning errors). Great care should be taken when using language model outputs, particularly in high-stakes contexts, with the exact protocol (such as human review, grounding with additional context, or avoiding high-stakes uses altogether) matching the needs of specific applications. See our System Card for details.

GPT-4 significantly reduces hallucinations relative to previous GPT-3.5 models (which have themselves been improving with continued iteration). GPT-4 scores 19 percentage points higher than our latest GPT-3.5 on our internal, adversarially-designed factuality evaluations (Figure 6).

### GPT-4 has unexpected abilities!

“Certain capabilities remain hard to predict. For example, the Inverse Scaling Prize proposed several tasks for which model performance decreases as a function of scale. Similarly to a recent result by Wei et al., we find that GPT-4 reverses this trend, as shown on one of the tasks called Hindsight Neglect in Figure 3.”

## Is GPT-4 API available?

<Img src="https://storage.googleapis.com/lablab-static-eu/images/blog/gpt-4-image-3.jpg" />

It is not publicly available, but you can sign up to the GPT-4 API waitlist. You can interact with it if you have ChatGPT plus and test all of the features yourself. Actually for me the image to text feature is one of the most interesting ones. And ofcourse the improved creativity capabilities of the model.

And as I mentioned before - if you have an early access to Bing’s chatbot you can as well play around with GPT-4, so there are some ways to see how the newest model outbeats the previous one.

If you want to know more about all of the features of GPT-4, go and read the research papers. The more you know the better!

And we encourage you to build with it. I mean, the API is not public yet, but why not design an app using GPT-3.5 and upgrade it as the GPT-4 API will be live? 

And where better to create your own app, than during our 7 days AI Hackathons! There is even AI Hackathon dedicated to Whisper’s and GPT-3.5 API!
